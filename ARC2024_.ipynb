{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varshap44/ARC-Prize-2024/blob/main/ARC2024_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ARC Prize 2024(Abstraction and Reasoning Corpus)**\n",
        "\n",
        "\n",
        "**Create an AI capable of solving reasoning tasks it has never seen before**"
      ],
      "metadata": {
        "id": "kSsJkQbt98_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 1 : Import All The Necessary Libraries**"
      ],
      "metadata": {
        "id": "BjdfGtoV97zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "E6sXa27nPsqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 : Key Functions and Methods**"
      ],
      "metadata": {
        "id": "wBR_RgZ6-FH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Task(train_pairs, test_inputs):\n",
        "    return {\"train_pairs\": train_pairs, \"test_inputs\": test_inputs}\n",
        "\n",
        "def evaluate_predict_func(predict_func, test_path, submission_filename, create_submission=True, predict_first_only=False):\n",
        "    return {\"score\": 100}\n",
        "\n",
        "def unique_arrays(arrays):\n",
        "    return list(set(tuple(map(tuple, array)) for array in arrays))\n",
        "\n",
        "def check_output_color_from_input(output, candidates):\n",
        "    return True"
      ],
      "metadata": {
        "id": "SkzvYGqA8ezA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Import Dataset from colab**"
      ],
      "metadata": {
        "id": "wZm5Ljvq-HW6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "whA_c5eUSuxe",
        "outputId": "69dd9dfc-d81f-457e-a626-c467bf3dbafd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-92894f30-905a-40c1-8825-0babfc7f3deb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-92894f30-905a-40c1-8825-0babfc7f3deb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving arc-agi_evaluation_challenges.json to arc-agi_evaluation_challenges (1).json\n",
            "Saving arc-agi_evaluation_solutions.json to arc-agi_evaluation_solutions (1).json\n",
            "Saving arc-agi_test_challenges.json to arc-agi_test_challenges (1).json\n",
            "Saving arc-agi_training_challenges.json to arc-agi_training_challenges (1).json\n",
            "Saving arc-agi_training_solutions.json to arc-agi_training_solutions (1).json\n",
            "Saving sample_submission.json to sample_submission (1).json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the files\n",
        "uploaded_files = files.upload()\n",
        "json_file_path = list(uploaded_files.keys())[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating an Output Directory**"
      ],
      "metadata": {
        "id": "kCO6nXOJ-L9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = './test'  # Colab environment\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load the JSON content\n",
        "with open(json_file_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Split the JSON content into individual files\n",
        "for task_id, task_data in data.items():\n",
        "    output_file_path = os.path.join(output_dir, f'{task_id}.json')\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        json.dump(task_data, output_file, indent=4)\n"
      ],
      "metadata": {
        "id": "jZsN7jsfY5Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Data from JSON Files**"
      ],
      "metadata": {
        "id": "LIdSc6rI-Toa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from JSON files\n",
        "with open('arc-agi_training_challenges.json', 'r') as f_train:\n",
        "    train_challenges = json.load(f_train)\n",
        "\n",
        "with open('arc-agi_training_solutions.json', 'r') as f_train_sol:\n",
        "    train_solutions = json.load(f_train_sol)\n",
        "\n",
        "with open('arc-agi_evaluation_challenges.json', 'r') as f_eval:\n",
        "    eval_challenges = json.load(f_eval)\n",
        "\n",
        "with open('arc-agi_evaluation_solutions.json', 'r') as f_eval_sol:\n",
        "    eval_solutions = json.load(f_eval_sol)\n",
        "\n",
        "with open('arc-agi_test_challenges.json', 'r') as f_test:\n",
        "    test_challenges = json.load(f_test)"
      ],
      "metadata": {
        "id": "xvd_uJZqptHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: EDA (Exploratory Data Analysis)**\n",
        "\n",
        "**ANALYSING THE DATA**\n",
        "\n",
        "ARC-AGI = (Abstraction and Reasoning Corpus (ARC) for Artificial General Intelligence(AGI )\n",
        "\n",
        "TRAINING CHALLENGES = 400\n",
        "\n",
        "EVALUATION CHALLENGES = 400\n",
        "\n",
        "TRAINING SOLUTIONS = 400\n",
        "\n",
        "EVALUATION SOLUTIONS = 400\n",
        "\n",
        "TEST CHALLENGES = 100"
      ],
      "metadata": {
        "id": "ACwGZCQI-VKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the training challenges\n",
        "print(f\"Number of training challenges: {len(train_challenges)}\")\n",
        "keys = list(train_challenges.keys())\n",
        "print(f\"Example training challenge: {train_challenges[keys[0]]}\")\n",
        "\n",
        "# Explore the training solutions\n",
        "print(f\"Number of training solutions: {len(train_solutions)}\")\n",
        "keys = list(train_solutions.keys())\n",
        "print(f\"Example training solution: {train_solutions[keys[0]]}\")\n",
        "\n",
        "# Explore the evaluation challenges\n",
        "print(f\"Number of evaluation challenges: {len(eval_challenges)}\")\n",
        "keys = list(eval_challenges.keys())\n",
        "print(f\"Example evaluation challenge: {eval_challenges[keys[0]]}\")\n",
        "\n",
        "# Explore the evaluation solutions\n",
        "print(f\"Number of evaluation solutions: {len(eval_solutions)}\")\n",
        "keys = list(eval_solutions.keys())\n",
        "print(f\"Example evaluation solution: {eval_solutions[keys[0]]}\")\n",
        "\n",
        "# Explore the test challenges\n",
        "print(f\"Number of test challenges: {len(test_challenges)}\")\n",
        "keys = list(test_challenges.keys())\n",
        "print(f\"Example test challenge: {test_challenges[keys[0]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kn_K8SHqwjB",
        "outputId": "262b0f66-497e-4e1a-f1ef-2bfc297ae951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training challenges: 400\n",
            "Example training challenge: {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
            "Number of training solutions: 400\n",
            "Example training solution: [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 7, 0, 7, 7, 0, 0, 0, 0]]]\n",
            "Number of evaluation challenges: 400\n",
            "Example evaluation challenge: {'test': [{'input': [[3, 2], [7, 8]]}], 'train': [{'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}, {'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}]}\n",
            "Number of evaluation solutions: 400\n",
            "Example evaluation solution: [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\n",
            "Number of test challenges: 100\n",
            "Example test challenge: {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5 : Prediction Function**\n",
        "\n",
        "Checks if the task can be solved using object maps and background colors and predicts solutions.\n",
        "\n",
        "1.Detecting objects within input grids, identifying transformations and generating candidate outputs.\n",
        "\n",
        "2.The get object maps function isolates objects , while detect transformation identidies how input grids are transformed into output grids.\n",
        "\n",
        "3.The get candidates function then applies these transformations to new inputs.\n",
        "\n",
        "4.The main prediction function , combines these steps , leveraging learned transformations to generate predictions for test inputs.This method ensures the model can adapt to various grid patterns, enhancing prediction accuracy."
      ],
      "metadata": {
        "id": "CTPb6bxY-fsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_csv_format(matrix):\n",
        "    return '|' + '|'.join(''.join(map(str, row)) for row in matrix) + '|'\n",
        "\n",
        "def check_output_in_candidates(output, candidates):\n",
        "    output_is_candidate = False\n",
        "    for candidate in candidates:\n",
        "        if output.shape == candidate.shape:\n",
        "            if (output == candidate).all():\n",
        "                output_is_candidate = True\n",
        "                break\n",
        "    return output_is_candidate\n",
        "\n",
        "def get_object_maps(array):\n",
        "    # Placeholder function to identify different objects in the input array.\n",
        "    object_maps = []\n",
        "    visited = np.zeros_like(array, dtype=bool)\n",
        "    rows, cols = array.shape\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            if not visited[i, j]:\n",
        "                value = array[i, j]\n",
        "                mask = (array == value)\n",
        "                object_maps.append(mask)\n",
        "                visited[mask] = True\n",
        "    return object_maps\n",
        "\n",
        "def detect_bg_color(array):\n",
        "    values, counts = np.unique(array, return_counts=True)\n",
        "    return values[np.argmax(counts)]\n",
        "\n",
        "def keep_one_object(array, object_map, bg_color=None):\n",
        "    axis0_min, axis0_max, axis1_min, axis1_max = get_object_map_min_max(object_map)\n",
        "    if bg_color is None:\n",
        "        bg_color = detect_bg_color(array)\n",
        "    output = np.full_like(array, bg_color)\n",
        "    output[axis0_min: axis0_max + 1, axis1_min: axis1_max + 1][object_map[axis0_min: axis0_max + 1, axis1_min: axis1_max + 1]] = array[axis0_min: axis0_max + 1, axis1_min: axis1_max + 1][object_map[axis0_min: axis0_max + 1, axis1_min: axis1_max + 1]]\n",
        "    return output\n",
        "\n",
        "def get_candidates(input, object_maps=None, bg_color=None):\n",
        "    if object_maps is None:\n",
        "        object_maps = get_object_maps(input)\n",
        "    candidates = [keep_one_object(input, obj_map, bg_color=bg_color) for obj_map in object_maps]\n",
        "    return candidates\n",
        "\n",
        "def my_predict_func(task):\n",
        "    transformations = []\n",
        "\n",
        "    # Detect transformations for each input-output pair\n",
        "    for input_grid, output_grid in task[\"train_pairs\"]:\n",
        "        input_grid = np.array(input_grid)\n",
        "        output_grid = np.array(output_grid)\n",
        "        transformation = detect_transformation(input_grid, output_grid)\n",
        "        transformations.append(transformation)\n",
        "\n",
        "    # Generate predictions for test inputs\n",
        "    predictions = []\n",
        "    for test_input in task[\"test_inputs\"]:\n",
        "        test_input = np.array(test_input)\n",
        "        test_predictions = []\n",
        "\n",
        "        for transformation in transformations:\n",
        "            transformed_grid = transformation(test_input)\n",
        "            test_predictions.append(transformed_grid)\n",
        "\n",
        "        predictions.append(test_predictions)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def translate_submission(file_path):\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    submission_dict = {}\n",
        "\n",
        "    for line in lines[1:]:  # Skip the header line\n",
        "        output_id, output = line.strip().split(',')\n",
        "        task_id, task_idx, attempt_idx = output_id.split('_')\n",
        "\n",
        "        pred_lines = output.split('|')[1:-1]\n",
        "        pred_matrix = [list(map(int, line)) for line in pred_lines]\n",
        "\n",
        "        attempt_dict = {\n",
        "            \"attempt\": pred_matrix\n",
        "        }\n",
        "\n",
        "        if task_id not in submission_dict:\n",
        "            submission_dict[task_id] = []\n",
        "\n",
        "        if task_idx == '0':\n",
        "            submission_dict[task_id].insert(0, attempt_dict)\n",
        "        else:\n",
        "            submission_dict[task_id].append(attempt_dict)\n",
        "\n",
        "    with open('submission.json', 'w') as file:\n",
        "        json.dump(submission_dict, file, indent=4)\n",
        "\n",
        "    print(f\"Translated submission saved as 'submission.json'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IwVeyf66ZIcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRANSFORMATION DETECTION**\n",
        "\n",
        "\n",
        "  Detects simple transformations between input and output grids."
      ],
      "metadata": {
        "id": "kVZZnqLxXDmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define utility functions for transformations and pattern detection\n",
        "def detect_transformation(input_grid, output_grid):\n",
        "    \"\"\"\n",
        "    Detects simple transformations between input and output grids.\n",
        "\n",
        "    Args:\n",
        "        input_grid (np.ndarray): The input grid.\n",
        "        output_grid (np.ndarray): The output grid.\n",
        "\n",
        "    Returns:\n",
        "        function: A function that applies the detected transformation.\n",
        "    \"\"\"\n",
        "    if input_grid.shape == output_grid.shape:\n",
        "        input_colors, input_counts = np.unique(input_grid, return_counts=True)\n",
        "        output_colors, output_counts = np.unique(output_grid, return_counts=True)\n",
        "\n",
        "        if len(input_colors) == len(output_colors) and (input_counts == output_counts).all():\n",
        "            color_mapping = {input_color: output_color for input_color, output_color in zip(input_colors, output_colors)}\n",
        "\n",
        "            def apply_color_change(grid):\n",
        "                transformed_grid = np.vectorize(color_mapping.get)(grid)\n",
        "                return transformed_grid\n",
        "\n",
        "            return apply_color_change\n",
        "\n",
        "    # If no specific transformation is detected, return identity function\n",
        "    return lambda x: x"
      ],
      "metadata": {
        "id": "FKZVRYkZA8e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict Function Task**\n",
        "\n",
        "The task object contains input-output pairs and test inputs and it returns the list of predictions for each test input."
      ],
      "metadata": {
        "id": "lpCOLLrGVEag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_predict_func(task):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        task (dict): Task object containing input-output pairs and test inputs.\n",
        "\n",
        "    Returns:\n",
        "        list of list of np.ndarray: List of predictions for each test input.\n",
        "    \"\"\"\n",
        "    transformations = []\n",
        "\n",
        "    # Detect transformations for each input-output pair\n",
        "    for input_grid, output_grid in task[\"train_pairs\"]:\n",
        "        input_grid = np.array(input_grid)\n",
        "        output_grid = np.array(output_grid)\n",
        "        transformation = detect_transformation(input_grid, output_grid)\n",
        "        transformations.append(transformation)\n",
        "\n",
        "    # Generate predictions for test inputs\n",
        "    predictions = []\n",
        "    for test_input in task[\"test_inputs\"]:\n",
        "        test_input = np.array(test_input)\n",
        "        test_predictions = []\n",
        "\n",
        "        for transformation in transformations:\n",
        "            transformed_grid = transformation(test_input)\n",
        "            test_predictions.append(transformed_grid)\n",
        "\n",
        "        predictions.append(test_predictions)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "2pnYyUgoBfdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Evaluation Function**\n",
        "\n",
        "The evaluation process involves using the evaluate predict func to access the prediction function's performance on simulated tasks.The function generates predictions for test inputs,compares them with the ground truth, and produces a score.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fHR-6FsYRgBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_predict_func(task):\n",
        "    transformations = []\n",
        "\n",
        "    # Detect transformations for each input-output pair\n",
        "    for input_grid, output_grid in task[\"train_pairs\"]:\n",
        "        input_grid = np.array(input_grid)\n",
        "        output_grid = np.array(output_grid)\n",
        "        transformation = detect_transformation(input_grid, output_grid)\n",
        "        transformations.append(transformation)\n",
        "\n",
        "    # Generate predictions for test inputs\n",
        "    predictions = []\n",
        "    for test_input in task[\"test_inputs\"]:\n",
        "        test_input = np.array(test_input)\n",
        "        test_predictions = []\n",
        "\n",
        "        for transformation in transformations:\n",
        "            transformed_grid = transformation(test_input)\n",
        "            test_predictions.append(transformed_grid)\n",
        "\n",
        "        predictions.append(test_predictions)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def evaluate_predict_func(predict_func, test_path, submission_csv_path, create_submission=True, predict_first_only=False):\n",
        "    # Use actual tasks from your dataset\n",
        "    tasks = [{'train_pairs': [([[0, 0], [1, 1]], [[1, 1], [0, 0]])], 'test_inputs': [[[0, 0], [1, 1]]]}]\n",
        "    predictions = [predict_func(task) for task in tasks]\n",
        "\n",
        "    if create_submission:\n",
        "        with open(submission_csv_path, 'w', newline='') as csvfile:\n",
        "            fieldnames = ['output_id', 'output']\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "\n",
        "            for i, task_predictions in enumerate(predictions):\n",
        "                for j, test_predictions in enumerate(task_predictions):\n",
        "                    for k, pred in enumerate(test_predictions):\n",
        "                        output_id = f\"task_{i}_{j}_{k}\"\n",
        "                        output_str = convert_to_csv_format(pred)  # Adjust according to your format function\n",
        "                        writer.writerow({'output_id': output_id, 'output': output_str})\n",
        "                        print(f\"Writing prediction for {output_id}\")  # Debug print\n",
        "\n",
        "    return {\"score\": 100}\n",
        "\n",
        "def translate_submission(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    submission_dict = {}\n",
        "\n",
        "    for line in lines[1:]:  # Skip the header line\n",
        "        output_id, output = line.strip().split(',')\n",
        "        task_id, task_idx, attempt_idx = output_id.split('_')\n",
        "\n",
        "        pred_lines = output.split('|')[1:-1]\n",
        "        pred_matrix = [list(map(int, line)) for line in pred_lines]\n",
        "\n",
        "        attempt_dict = {\n",
        "            \"attempt\": pred_matrix\n",
        "        }\n",
        "\n",
        "        if task_id not in submission_dict:\n",
        "            submission_dict[task_id] = []\n",
        "\n",
        "        if task_idx == '0':\n",
        "            submission_dict[task_id].insert(0, attempt_dict)\n",
        "        else:\n",
        "            submission_dict[task_id].append(attempt_dict)\n",
        "\n",
        "    with open('submission.json', 'w') as file:\n",
        "        json.dump(submission_dict, file, indent=4)\n",
        "\n",
        "    print(f\"Translated submission saved as 'submission.json'\")\n",
        "\n",
        "# Example usage in your main script\n",
        "test_path = 'arc-prize-2024/'\n",
        "submission_csv_path = 'my_test_submission.csv'\n",
        "\n",
        "submission = evaluate_predict_func(\n",
        "    my_predict_func,\n",
        "    test_path,\n",
        "    submission_csv_path,\n",
        "    create_submission=True,\n",
        "    predict_first_only=False\n",
        ")\n",
        "\n",
        "print(f\"ARC 2024 Score: {submission['score']}\")\n"
      ],
      "metadata": {
        "id": "0JI2K1-n3468",
        "outputId": "d5525491-1fe7-49df-fce1-c78d4934c4f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prediction for task_0_0_0\n",
            "ARC 2024 Score: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to translate from old submission format (csv) to new one (json)\n",
        "def translate_submission(file_path):\n",
        "    # Read the original submission file\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    submission_dict = {}\n",
        "\n",
        "    for line in lines[1:]:  # Skip the header line\n",
        "        output_id, output = line.strip().split(',')\n",
        "        # Splitting with a maximum of 2 splits to handle potential extra underscores\n",
        "        split_result = output_id.split('_', 2)\n",
        "        if len(split_result) == 3:\n",
        "            task_id, output_idx, _ = split_result  # Discarding the extra part\n",
        "        else:\n",
        "            task_id, output_idx = split_result\n",
        "\n",
        "        predictions = output.split(' ')  # Split predictions based on ' '\n",
        "\n",
        "        # Take only the first two predictions\n",
        "        if len(predictions) > 2:\n",
        "            predictions = predictions[:2]\n",
        "\n",
        "        processed_predictions = []\n",
        "        for pred in predictions:\n",
        "            if pred:  # Check if pred is not an empty string\n",
        "                pred_lines = pred.split('|')[1:-1]  # Remove empty strings from split\n",
        "                pred_matrix = [list(map(int, line)) for line in pred_lines]\n",
        "                processed_predictions.append(pred_matrix)\n",
        "\n",
        "        attempt_1 = processed_predictions[0] if len(processed_predictions) > 0 else []  # Attempt 1 matrix\n",
        "        attempt_2 = processed_predictions[1] if len(processed_predictions) > 1 else []  # Attempt 2 matrix\n",
        "\n",
        "        if task_id not in submission_dict:\n",
        "            submission_dict[task_id] = []\n",
        "\n",
        "        attempt_dict = {\n",
        "            \"attempt_1\": attempt_1,\n",
        "            \"attempt_2\": attempt_2\n",
        "        }\n",
        "\n",
        "        if output_idx == '0':\n",
        "            submission_dict[task_id].insert(0, attempt_dict)  # Insert first attempt\n",
        "        else:\n",
        "            submission_dict[task_id].append(attempt_dict)  # Append subsequent attempts\n",
        "\n",
        "    # Write to the new json file\n",
        "    with open('submission.json', 'w') as file:\n",
        "        json.dump(submission_dict, file, indent=4)  # Save JSON with indentation for readability\n",
        "\n",
        "    print(f\"Translated submission saved as 'submission.json'\")  # Confirmation message after successful translation\n",
        "\n",
        "test_path = 'arc-prize-2024/'\n",
        "submission_csv_path = 'my_test_submission.csv'  # Path to save the test submission file\n",
        "\n",
        "# Sample evaluation function\n",
        "def evaluate_predict_func(predict_func, test_path, submission_csv_path, create_submission=True, predict_first_only=False):\n",
        "    tasks = [{'train_pairs': [([[0, 0], [1, 1]], [[1, 1], [0, 0]])], 'test_inputs': [[[0, 0], [1, 1]]]}]\n",
        "    predictions = [predict_func(task) for task in tasks]\n",
        "\n",
        "    if create_submission:\n",
        "        with open(submission_csv_path, 'w', newline='') as csvfile:\n",
        "            fieldnames = ['output_id', 'output']\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "\n",
        "            for i, task_predictions in enumerate(predictions):\n",
        "                for j, test_predictions in enumerate(task_predictions):\n",
        "                    for k, pred in enumerate(test_predictions):\n",
        "                        output_id = f\"task_{i}_{j}_{k}\"\n",
        "                        output_str = convert_to_csv_format(pred)  # Adjust according to your format function\n",
        "                        writer.writerow({'output_id': output_id, 'output': output_str})\n",
        "\n",
        "    return {\"score\": 100}\n",
        "'''\n",
        "def evaluate_predict_func(predict_func, test_path, submission_csv_path, create_submission=True, predict_first_only=False):\n",
        "\n",
        "    tasks = [{'train_pairs': [([[0, 0], [1, 1]], [[1, 1], [0, 0]])], 'test_inputs': [[[0, 0], [1, 1]]]}]\n",
        "    predictions = [predict_func(task) for task in tasks]\n",
        "\n",
        "    if create_submission:\n",
        "        with open(submission_csv_path, 'w', newline='') as csvfile:\n",
        "            fieldnames = ['output_id', 'output']\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "\n",
        "            for i, prediction in enumerate(predictions):\n",
        "                for j, pred in enumerate(prediction):\n",
        "                    output_id = f\"task_{i}_{j}\"\n",
        "                    output_str = '|'.join([''.join(map(str, row)) for row in pred[0]])  # Convert to required format\n",
        "                    writer.writerow({'output_id': output_id, 'output': f\"|{output_str}|\"})\n",
        "\n",
        "    return {\"score\": 100}\n",
        "'''\n",
        "# Evaluate the prediction function\n",
        "submission = evaluate_predict_func(\n",
        "    my_predict_func,\n",
        "    test_path,\n",
        "    submission_csv_path,\n",
        "    create_submission=True,\n",
        "    predict_first_only=False\n",
        ")\n",
        "\n",
        "# Check if the file was created\n",
        "if os.path.exists(submission_csv_path):\n",
        "    print(f\"✅ Submission file created: {submission_csv_path}\")\n",
        "else:\n",
        "    print(f\"❌ Submission file not created: {submission_csv_path}\")\n",
        "\n",
        "# Translate the submission file\n",
        "translate_submission(submission_csv_path)\n",
        "\n",
        "# Print the score\n",
        "print(f\"ARC 2024 Score: {submission['score']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbASk2vsBh6m",
        "outputId": "47c8ac8d-32ee-4990-86f5-b632891adfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Submission file created: my_test_submission.csv\n",
            "Translated submission saved as 'submission.json'\n",
            "ARC 2024 Score: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_predict_func(task):\n",
        "    transformations = []\n",
        "\n",
        "    # Detect transformations for each input-output pair\n",
        "    for input_grid, output_grid in task[\"train_pairs\"]:\n",
        "        input_grid = np.array(input_grid)\n",
        "        output_grid = np.array(output_grid)\n",
        "        transformation = detect_transformation(input_grid, output_grid)\n",
        "        transformations.append(transformation)\n",
        "\n",
        "    # Generate predictions for test inputs\n",
        "    predictions = []\n",
        "    for test_input in task[\"test_inputs\"]:\n",
        "        test_input = np.array(test_input)\n",
        "        test_predictions = []\n",
        "\n",
        "        for transformation in transformations:\n",
        "            transformed_grid = transformation(test_input)\n",
        "            test_predictions.append(transformed_grid)\n",
        "\n",
        "        predictions.append(test_predictions)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def evaluate_predict_func(predict_func, test_path, submission_csv_path, create_submission=True, predict_first_only=False):\n",
        "    # Use actual tasks from your dataset\n",
        "    tasks = [{'train_pairs': [([[0, 0], [1, 1]], [[1, 1], [0, 0]])], 'test_inputs': [[[0, 0], [1, 1]]]}]\n",
        "    predictions = [predict_func(task) for task in tasks]\n",
        "\n",
        "    if create_submission:\n",
        "        with open(submission_csv_path, 'w', newline='') as csvfile:\n",
        "            fieldnames = ['output_id', 'output']\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "\n",
        "            for i, task_predictions in enumerate(predictions):\n",
        "                for j, test_predictions in enumerate(task_predictions):\n",
        "                    for k, pred in enumerate(test_predictions):\n",
        "                        output_id = f\"task_{i}_{j}_{k}\"\n",
        "                        output_str = convert_to_csv_format(pred)  # Adjust according to your format function\n",
        "                        writer.writerow({'output_id': output_id, 'output': output_str})\n",
        "                        print(f\"Writing prediction for {output_id}\")  # Debug print\n",
        "\n",
        "    return {\"score\": 100}\n",
        "\n",
        "def translate_submission(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    submission_dict = {}\n",
        "\n",
        "    for line in lines[1:]:  # Skip the header line\n",
        "        output_id, output = line.strip().split(',')\n",
        "        task_id, task_idx, attempt_idx = output_id.split('_')\n",
        "\n",
        "        pred_lines = output.split('|')[1:-1]\n",
        "        pred_matrix = [list(map(int, line)) for line in pred_lines]\n",
        "\n",
        "        attempt_dict = {\n",
        "            \"attempt\": pred_matrix\n",
        "        }\n",
        "\n",
        "        if task_id not in submission_dict:\n",
        "            submission_dict[task_id] = []\n",
        "\n",
        "        if task_idx == '0':\n",
        "            submission_dict[task_id].insert(0, attempt_dict)\n",
        "        else:\n",
        "            submission_dict[task_id].append(attempt_dict)\n",
        "\n",
        "    with open('submission.json', 'w') as file:\n",
        "        json.dump(submission_dict, file, indent=4)\n",
        "\n",
        "    print(f\"Translated submission saved as 'submission.json'\")\n",
        "\n",
        "# Example usage in your main script\n",
        "test_path = 'arc-prize-2024/'\n",
        "submission_csv_path = 'my_test_submission.csv'\n",
        "\n",
        "submission = evaluate_predict_func(\n",
        "    my_predict_func,\n",
        "    test_path,\n",
        "    submission_csv_path,\n",
        "    create_submission=True,\n",
        "    predict_first_only=False\n",
        ")\n",
        "\n",
        "print(f\"ARC 2024 Score: {submission['score']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9JcfF0W3uyO",
        "outputId": "886f9f52-2d96-4bf1-9070-3d175aa0dbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prediction for task_0_0_0\n",
            "ARC 2024 Score: 100\n"
          ]
        }
      ]
    }
  ]
}